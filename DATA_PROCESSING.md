# ğŸ“¦ Pasos de Preprocesamiento - LARVASCNN ğŸ—ï¸

Este documento explica la secuencia recomendada para procesar tus imÃ¡genes y anotaciones, generando un conjunto de datos unificado para **YOLOv8**. Los scripts se ejecutan **por cada** subcarpeta de celular (`cel_bb`, `cel_ed`, `cel_smsnga30`), resultando en carpetas `train/` y `valid/` listas para entrenamiento, las cuales finalmente se unen en `datasets/final_postlarva_dataset_yolov8/`.

---

## 1ï¸âƒ£ ReplicaciÃ³n de Histograma (`replicate_histogram.py`) ğŸŒˆ

Este script ajusta el histograma de tus imÃ¡genes usando referencias en formato `.npy`.

- **Objetivo**: Estandarizar la iluminaciÃ³n y el contraste antes de otros pasos.

**Ejemplo de uso** (para la carpeta `cel_bb`):

```bash
python replicate_histogram.py --input_path datasets/raw_postlarva_data/cel_bb --input_json annotations.json --output_path datasets/processed/cel_bb/hist_equalized --output_json hist_equalized_annotations.json --set train
```

1. **`--input_path`**: Ruta donde estÃ¡n tus imÃ¡genes y `annotations.json`.
2. **`--input_json`**: Nombre del JSON de anotaciones en formato COCO.
3. **`--output_path`**: Carpeta de salida para las imÃ¡genes con histograma ajustado.
4. **`--output_json`**: Nombre para el nuevo archivo de anotaciones (ajustado si fuera el caso).
5. **`--set`**: ParÃ¡metro extra (por ejemplo "train") para etiquetar.

Repite el proceso para `cel_ed` y `cel_smsnga30`, apuntando a sus rutas correspondientes.

---

## 2ï¸âƒ£ GeneraciÃ³n de Teselas (`generate_tiles.py`) ğŸ§©

Corta las imÃ¡genes en teselas (ej. 640Ã—640) con un porcentaje de solapamiento. AsÃ­ se obtienen mÃºltiples recortes y se actualizan las anotaciones.

- **Objetivo**: Trabajar con recortes manejables, optimizando el entrenamiento.

**Ejemplo de uso** (luego de replicar histograma en `cel_bb`):

```bash
python generate_tiles.py --input_path datasets/processed/cel_bb/hist_equalized --input_json hist_equalized_annotations.json --output_path datasets/processed/cel_bb/tiles_640x640 --output_json tiles_annotations.json --tile_width 640 --tile_height 640 --overlap 0.5 --single_class True
```

ParÃ¡metros principales:

- **`--tile_width`** y **`--tile_height`**: Dimensiones en pÃ­xeles de cada tesela (por defecto 640Ã—640).
- **`--overlap`**: Porcentaje de solapamiento (0.5 = 50%).
- **`--single_class`**: Si deseas unificar las categorÃ­as en una sola (ej. para "objeto_interÃ©s").

Repite para `cel_ed` y `cel_smsnga30`.

---

## 3ï¸âƒ£ Desenfoque y RotaciÃ³n (`blur_rotation.py`) ğŸ¨

Aplica desenfoque (*blur*) y rotaciones. Dependiendo de tu lÃ³gica interna, el script puede recalcular o no los *bounding boxes* tras la rotaciÃ³n.

- **Objetivo**: Aumentar la variabilidad de las imÃ¡genes para un entrenamiento mÃ¡s robusto.

**Ejemplo de uso** (con la carpeta de teselas de `cel_bb`):

```bash
python blur_rotation.py --input_path datasets/processed/cel_bb/tiles_640x640 --input_json tiles_annotations.json --output_path datasets/processed/cel_bb/blurred_rotated --set train --total_cores 6
```

- **`--input_path`**: Ruta de las imÃ¡genes a modificar (y su JSON).
- **`--output_path`**: Carpeta donde se guardan las imÃ¡genes desenfocadas y/o rotadas.
- **`--set`**: Puede usarse para diferenciar si es `train`, `valid`, etc.
- **`--total_cores`**: NÃºmero de hilos para el procesamiento en paralelo.

### ğŸ—’ï¸ Sugerencias de `total_cores` segÃºn tu equipo

| **Tipo de Equipo**    | **`total_cores` Aproximado** |
|-----------------------|-------------------------------|
| **Supercomputadora**  | 32 o mÃ¡s (dependiendo del cluster) |
| **Workstation**       | 8 a 16 nÃºcleos               |
| **Laptop Gaming**     | ~8 nÃºcleos                   |
| **Laptop Normal**     | 2 a 4 nÃºcleos                |

Repite para `cel_ed` y `cel_smsnga30`.

---

## 4ï¸âƒ£ Dividir en Train/Valid (`split_train_val.py`) ğŸ—‚ï¸

Toma las imÃ¡genes y sus archivos `.txt` (si en tu flujo ya tienes anotaciones en formato YOLO) o las anotaciones correspondientes, y crea dos carpetas: `train/` y `valid/`.

- Genera subcarpetas `images/` y `labels/` dentro de cada una, copiando lo necesario.

**Ejemplo de uso** (despuÃ©s de `blur_rotation.py` en `cel_bb`):

```bash
python split_train_val.py --input_path datasets/processed/cel_bb/blurred_rotated --output_path datasets/pre_final_postlarva_dataset_yolov8/cel_bb --train_ratio 0.8 --val_ratio 0.2
```

- **`--train_ratio`** y **`--val_ratio`** controlan la proporciÃ³n de datos para entrenamiento y validaciÃ³n.
- Crea las carpetas:
  ```
  datasets/pre_final_postlarva_dataset_yolov8/
    â””â”€â”€ cel_bb/
        â”œâ”€â”€ train/
        â”‚   â”œâ”€â”€ images/
        â”‚   â””â”€â”€ labels/
        â””â”€â”€ valid/
            â”œâ”€â”€ images/
            â””â”€â”€ labels/
  ```

Repite para `cel_ed` y `cel_smsnga30`.

---

## 5ï¸âƒ£ Unir todo en `final_postlarva_dataset_yolov8` (Obligatorio) ğŸ

Una vez tengas cada carpeta (`cel_bb`, `cel_ed`, `cel_smsnga30`) con su respectivo `train/` y `valid/` en `datasets/pre_final_postlarva_dataset_yolov8/`, debes **unificar todos** los datos en `datasets/final_postlarva_dataset_yolov8/`. De esta forma, YOLOv8 los leerÃ¡ como un solo conjunto.

La estructura final quedarÃ¡ asÃ­:

```
datasets/final_postlarva_dataset_yolov8/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â””â”€â”€ valid/
    â”œâ”€â”€ images/
    â””â”€â”€ labels/
```

- Copia y combina el contenido de `train/images/`, `train/labels/`, `valid/images/`, y `valid/labels/` de **todas** las subcarpetas en un solo `train/` y `valid/`.
- AsegÃºrate de que no haya conflictos de nombres. En caso de colisiÃ³n, puedes renombrar los archivos.

---

## Flujo Resumido ğŸš€

1. **`replicate_histogram.py`** â†’ Ajusta histograma (ej. `cel_bb`)
2. **`generate_tiles.py`** â†’ Genera teselas (640Ã—640)
3. **`blur_rotation.py`** â†’ Aplica desenfoque y rotaciones
4. **`split_train_val.py`** â†’ Crea `train/` y `valid/` en `datasets/pre_final_postlarva_dataset_yolov8/cel_*`
5. **Unir carpetas** â†’ Combina todo en `datasets/final_postlarva_dataset_yolov8/` (carpetas `train/` y `valid/`)

Se repiten los 4 primeros pasos para cada subcarpeta (`cel_bb`, `cel_ed`, `cel_smsnga30`) y luego **obligatoriamente** se realiza el paso 5 para unificar en un solo dataset global.

---

## ğŸ¯ Prueba de Entrenamiento

1. Ajusta tu archivo `.yaml` para YOLOv8 con:
   ```yaml
   train: datasets/final_postlarva_dataset_yolov8/train/images
   val: datasets/final_postlarva_dataset_yolov8/valid/images
   test: datasets/final_postlarva_dataset_yolov8/valid/images
   nc: 1
   names: ["postlarva"]
   ```
2. Ejecuta:
   ```bash
   python tutorial_training_yolov8.py
   ```
3. Observa las mÃ©tricas (mAP, precisiÃ³n, etc.) al finalizar.

Con estos **5 pasos**, tu dataset quedarÃ¡ **unificado y listo** para entrenar un modelo YOLOv8 que reconozca **postlarvas de gamitana** capturadas con distintos celulares ğŸ“¸ğŸŸ.
